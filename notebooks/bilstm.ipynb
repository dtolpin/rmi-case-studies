{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Can we just learn the function instead of deriving algorithms?\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import sys\n",
    "import os.path\n",
    "import torch.nn\n",
    "import torch.optim\n",
    "import torch.utils.data\n",
    "from torch.autograd import Variable\n",
    "import numpy\n",
    "import numpy.random\n",
    "import scipy\n",
    "from sklearn import metrics\n",
    "import matplotlib.pyplot as plt\n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "DATADIR = \"../data\"\n",
    "FEATRS = [\"s-collected-negative.npy\", \"s-collected-positive.npy\"]\n",
    "LABELS = [\"z-collected-negative.npy\", \"z-collected-positive.npy\"]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Load the data."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "data = []\n",
    "for fname, lname in zip(FEATRS, LABELS):\n",
    "    f = numpy.load(os.path.join(DATADIR, fname))\n",
    "    l = numpy.load(os.path.join(DATADIR, lname))\n",
    "    l = numpy.expand_dims(l, 2)\n",
    "    data.append(numpy.concatenate([f, l], axis=2))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Take the same fraction from each part as the training set."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "TRAIN_FRACTION = 0.8\n",
    "BATCH_SIZE = 16\n",
    "LEARNING_RATE = 0.001\n",
    "NEPOCHS = 50\n",
    "HIDDEN_SIZE = 64\n",
    "NUM_LAYERS = 3\n",
    "BIDIRECTIONAL = True"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_data = []\n",
    "test_data = []\n",
    "for part in data:\n",
    "    indices = numpy.arange(len(part))\n",
    "    numpy.random.shuffle(indices)\n",
    "    train_end = int(len(indices) * TRAIN_FRACTION)\n",
    "    train_data.append(part[indices[:train_end]])\n",
    "    test_data.append(part[indices[train_end:]])\n",
    "train_data = numpy.concatenate(train_data, axis=0)\n",
    "test_data = numpy.concatenate(test_data, axis=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_loader = torch.utils.data.DataLoader(\n",
    "    train_data,\n",
    "    batch_size=BATCH_SIZE,\n",
    "    shuffle=True)\n",
    "test_loader = torch.utils.data.DataLoader(\n",
    "    test_data,\n",
    "    batch_size=BATCH_SIZE,\n",
    "    shuffle=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The model is a multilayer LSTM, used to classify entries into regular and containing intrusion. We do not have enough positive intrusion event labels to detect individual events, so only overall intrusion/no intrusion classification is learned."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Model(torch.nn.Module):\n",
    "    def __init__(self):\n",
    "        super(Model, self).__init__()\n",
    "        self.lstm = torch.nn.LSTM(2, HIDDEN_SIZE, NUM_LAYERS, bidirectional=BIDIRECTIONAL)\n",
    "        self.readout = torch.nn.Linear(HIDDEN_SIZE, 1)\n",
    "        \n",
    "    def forward(self, x):\n",
    "        _, (h, _) = self.lstm(x)\n",
    "        result = self.readout(h[-1])\n",
    "        return result"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "def makexy(batch):\n",
    "    batch = batch.float()\n",
    "    x = Variable(batch[:, :, :2])\n",
    "    y = Variable(batch[:, :, 2:].sum(dim=0).sign())\n",
    "    return x, y"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = Model()\n",
    "optimizer = torch.optim.Adam(model.parameters(), lr=LEARNING_RATE)\n",
    "\n",
    "train_loss = numpy.nan\n",
    "test_loss =numpy.nan\n",
    "\n",
    "# Train/test loop\n",
    "iepoch = 0\n",
    "loss_function = torch.nn.BCEWithLogitsLoss()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/dvd/miniconda3/lib/python3.6/site-packages/ipykernel_launcher.py:14: UserWarning: invalid index of a 0-dim tensor. This will be an error in PyTorch 0.5. Use tensor.item() to convert a 0-dim tensor to a Python number\n",
      "  \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch    0: train loss: nan test loss: 0.660936\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/dvd/miniconda3/lib/python3.6/site-packages/ipykernel_launcher.py:40: UserWarning: invalid index of a 0-dim tensor. This will be an error in PyTorch 0.5. Use tensor.item() to convert a 0-dim tensor to a Python number\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch    1: train loss: 0.530186 test loss: 0.469356\n",
      "epoch    2: train loss: 0.482858 test loss: 0.441877\n",
      "epoch    3: train loss: 0.455149 test loss: 0.442864\n",
      "epoch    4: train loss: 0.460862 test loss: 0.436243\n",
      "epoch    5: train loss: 0.453052 test loss: 0.435263\n",
      "epoch    6: train loss: 0.451168 test loss: 0.430518\n",
      "epoch    7: train loss: 0.441288 test loss: 0.466721\n",
      "epoch    8: train loss: 0.443431 test loss: 0.426291\n",
      "epoch    9: train loss: 0.449675 test loss: 0.437495\n",
      "epoch   10: train loss: 0.440619 test loss: 0.442427\n",
      "epoch   11: train loss: 0.454302 test loss: 0.425464\n",
      "epoch   12: train loss: 0.444026 test loss: 0.426864\n",
      "epoch   13: train loss: 0.442875 test loss: 0.424933\n",
      "epoch   14: train loss: 0.439988 test loss: 0.425792\n",
      "epoch   15: train loss: 0.443026 test loss: 0.420014\n",
      "epoch   16: train loss: 0.442624 test loss: 0.42562\n",
      "epoch   17: train loss: 0.447239 test loss: 0.421528\n",
      "epoch   18: train loss: 0.435675 test loss: 0.415856\n",
      "epoch   19: train loss: 0.435902 test loss: 0.42395\n",
      "epoch   20: train loss: 0.438857 test loss: 0.427098\n",
      "epoch   21: train loss: 0.439297 test loss: 0.425182\n",
      "epoch   22: train loss: 0.438336 test loss: 0.416827\n",
      "epoch   23: train loss: 0.443534 test loss: 0.419872\n",
      "epoch   24: train loss: 0.434962 test loss: 0.424071\n",
      "epoch   25: train loss: 0.435963 test loss: 0.425511\n",
      "epoch   26: train loss: 0.445619 test loss: 0.423409\n",
      "epoch   27: train loss: 0.444804 test loss: 0.417132\n",
      "epoch   28: train loss: 0.43875 test loss: 0.41962\n",
      "epoch   29: train loss: 0.439998 test loss: 0.417802\n",
      "epoch   30: train loss: 0.438818 test loss: 0.417756\n",
      "epoch   31: train loss: 0.43206 test loss: 0.424807\n",
      "epoch   32: train loss: 0.435442 test loss: 0.411794\n",
      "epoch   33: train loss: 0.440922 test loss: 0.419235\n",
      "epoch   34: train loss: 0.430389 test loss: 0.415864\n",
      "epoch   35: train loss: 0.440313 test loss: 0.424924\n",
      "epoch   36: train loss: 0.429949 test loss: 0.423668\n",
      "epoch   37: train loss: 0.443554 test loss: 0.414013\n",
      "epoch   38: train loss: 0.441965 test loss: 0.421721\n",
      "epoch   39: train loss: 0.440119 test loss: 0.420029\n",
      "epoch   40: train loss: 0.437333 test loss: 0.415143\n",
      "epoch   41: train loss: 0.435502 test loss: 0.418434\n",
      "epoch   42: train loss: 0.437536 test loss: 0.417557\n",
      "epoch   43: train loss: 0.436629 test loss: 0.417906\n",
      "epoch   44: train loss: 0.440271 test loss: 0.423606\n",
      "epoch   45: train loss: 0.429018 test loss: 0.416161\n",
      "epoch   46: train loss: 0.433883 test loss: 0.423244\n",
      "epoch   47: train loss: 0.43702 test loss: 0.411532\n",
      "epoch   48: train loss: 0.435707 test loss: 0.415136\n",
      "epoch   49: train loss: 0.42924 test loss: 0.417045\n",
      "epoch   50: train loss: 0.439138 test loss: 0.421535\n"
     ]
    }
   ],
   "source": [
    "first_epoch = iepoch\n",
    "while True:\n",
    "    # Validate and test the model\n",
    "    model.eval()\n",
    "    test_loss = 0.\n",
    "    for batch in test_loader:\n",
    "        x, y = makexy(batch)\n",
    "        \n",
    "        # forward\n",
    "        result = model(x)\n",
    "\n",
    "        # loss\n",
    "        batch_loss = loss_function(result, y)\n",
    "        test_loss += batch_loss.data[0] * len(batch)\n",
    "\n",
    "    test_loss /= len(test_loader.dataset)\n",
    "\n",
    "    print(\"epoch {:4d}: train loss: {:.6g} test loss: {:.6g}\"\n",
    "          .format(iepoch, train_loss, test_loss))\n",
    "    sys.stdout.flush()\n",
    "\n",
    "    if iepoch == NEPOCHS + first_epoch:\n",
    "        break\n",
    "    iepoch += 1\n",
    "\n",
    "    # Train the model\n",
    "    model.train()\n",
    "    train_loss = 0.\n",
    "    for batch in train_loader:\n",
    "        optimizer.zero_grad()\n",
    "\n",
    "        x, y = makexy(batch)\n",
    "\n",
    "        # forward\n",
    "        result = model(x)\n",
    "        preds = result[0]\n",
    "\n",
    "        # loss\n",
    "        batch_loss = loss_function(result, y)\n",
    "        train_loss += batch_loss.data[0] * len(batch)\n",
    "\n",
    "        # backward\n",
    "        batch_loss.backward()\n",
    "        optimizer.step()\n",
    "\n",
    "    train_loss /= len(train_loader.dataset)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([50, 200, 2]) torch.Size([200, 1])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/dvd/miniconda3/lib/python3.6/site-packages/torch/tensor.py:255: UserWarning: non-inplace resize is deprecated\n",
      "  warnings.warn(\"non-inplace resize is deprecated\")\n"
     ]
    }
   ],
   "source": [
    "model.eval()\n",
    "x, y = makexy(torch.from_numpy(test_data.transpose(1, 0, 2)))\n",
    "y = y.data.resize(len(y))\n",
    "result = torch.nn.Sigmoid()(model(x)).data\n",
    "result = result.resize(len(result))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let us draw ROC on the training set and compute the AUC."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Text(0.5,1,'auc = 0.6016')"
      ]
     },
     "execution_count": 30,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "fpr, tpr, thresholds = metrics.roc_curve(y.data, result, pos_label=True)\n",
    "plt.plot(fpr, tpr)\n",
    "auc = metrics.auc(fpr, tpr)\n",
    "plt.title(\"auc = {:.4f}\".format(auc))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The accuracy is similar to detecting based on marks only. The use of deep learning is still possible but more complicated than just training an LSTM-based classifier."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
